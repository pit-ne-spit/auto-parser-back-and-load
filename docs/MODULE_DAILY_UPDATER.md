# Модуль ежедневного обновления данных

## Описание

Модуль `DailyUpdater` предназначен для ежедневного обновления данных из API CHE168.COM. Он получает изменения (новые объявления, изменения существующих, удаленные объявления) за предыдущий день и обновляет базу данных.

## Расположение

- **Класс:** `app.loaders.daily_updater.DailyUpdater`
- **Скрипт запуска:** `scripts/daily_update.py`
- **Базовый класс:** `app.loaders.base_loader.BaseLoader`

## Логика работы

### 1. Инициализация

```python
updater = DailyUpdater(max_dates=None)
```

**Параметры:**
- `max_dates` (Optional[int]): Максимальное количество дат для обработки. Если `None`, обрабатывается одна дата (вчерашний день). Используется для тестирования.

### 2. Определение даты для обработки

1. Вычисляется дата: `сегодня - 1 день` (вчерашний день)
2. Проверяется таблица `sync_state`:
   - Если дата уже обработана (`last_successful_date >= process_date`), процесс завершается
   - Если дата не обработана, продолжается обработка

### 3. Получение начального change_id

1. Выполняется запрос к `/change_id?date=YYYY-MM-DD` для получения начального `change_id`
2. `change_id` - это идентификатор, с которого начинается получение изменений для указанной даты
3. Если `change_id` не получен, процесс завершается (нет изменений за эту дату)

### 4. Пагинация изменений

#### Шаг 1: Запрос изменений

1. Выполняется запрос к `/changes?change_id={current_change_id}`
2. Используется rate limiting: пауза 2 секунды между запросами
3. Запросы выполняются через `asyncio.to_thread()`

#### Шаг 2: Обработка ответа

1. Извлекается массив `result` с изменениями
2. Из `meta` извлекается:
   - `cur_change_id` - текущий обработанный change_id
   - `next_change_id` - следующий change_id для продолжения пагинации
3. Если `next_change_id` равен `None`, пагинация завершается

#### Шаг 3: Обработка изменений

Для каждого изменения из `result` обрабатывается в зависимости от `change_type`:

##### change_type: "added" (новое объявление)

1. **Проверка дубликатов:**
   - Если запись с таким `inner_id` уже существует, она пропускается (дубликат)

2. **Создание новой записи:**
   - Все поля заполняются как при первоначальной загрузке
   - `source` = "daily_update"
   - `active_status` = 0 (активное)
   - `is_processed` = False (требует нормализации)

##### change_type: "changed" (изменение существующего объявления)

1. **Поиск существующей записи:**
   - Ищется запись по `inner_id`

2. **Обновление существующей записи:**
   - Выполняется merge JSON данных:
     - Существующие данные объединяются с новыми
     - Поля с префиксом `new_` (например, `new_price`) маппятся в поля без префикса (`price`)
     - Используется функция `merge_json()` из `app.utils.json_merger`
   - Обновляются поля:
     - `change_type` = "changed"
     - `created_at` = дата из API
     - `data` = объединенные данные
     - `last_updated_at` = текущее время UTC
     - `is_processed` = False (требует повторной нормализации)

3. **Edge case - запись не найдена:**
   - Если записи с таким `inner_id` нет, создается новая запись
   - Это может произойти, если объявление было удалено из БД или не было загружено ранее

##### change_type: "removed" (удаленное объявление)

1. **Поиск существующей записи:**
   - Ищется запись по `inner_id`

2. **Пометка как неактивное:**
   - `change_type` = "removed"
   - `active_status` = 1 (неактивное)
   - `last_updated_at` = текущее время UTC
   - `is_processed` = False (требует обновления в processed_data)

3. **Edge case - запись не найдена:**
   - Если записи с таким `inner_id` нет, создается новая запись с `active_status` = 1
   - Это может произойти, если объявление было удалено до первоначальной загрузки

#### Шаг 4: Коммит транзакции

- Все изменения со страницы сохраняются в одной транзакции
- При ошибке коммита выполняется rollback

#### Шаг 5: Продолжение пагинации

- Если `next_change_id` не `None`, процесс повторяется с новым `change_id`
- Пагинация продолжается до тех пор, пока `next_change_id` не станет `None`

### 5. Обновление sync_state

После успешной обработки всех страниц:

1. Обновляется или создается запись в таблице `sync_state`:
   - `last_successful_date` = обработанная дата
   - `last_change_id` = последний обработанный `change_id`
   - `updated_at` = текущее время UTC

2. Это позволяет при следующем запуске:
   - Определить, какие даты уже обработаны
   - Продолжить с нужного места при пропуске дней

### 6. Обработка ошибок

1. **Ошибки при получении change_id:**
   - Логируются через `record_error()`
   - Процесс завершается со статусом "ERROR"

2. **Ошибки при обработке страницы:**
   - Логируются с указанием номера страницы
   - Процесс прерывается (не обновляется `sync_state`)

3. **Ошибки при обработке записи:**
   - Логируются с указанием `inner_id`
   - Запись пропускается
   - Увеличивается счетчик ошибок

### 7. Отображение прогресса

В логи выводится прогресс в формате:
```
[INFO] Daily update: Page 5 | Records: 100 | Loaded: 20 | Updated: 60 | Removed: 20 | Duplicates: 0
```

## Использование

### Базовый запуск

```bash
python scripts/daily_update.py
```

Обрабатывает изменения за вчерашний день.

### Тестовый запуск

```bash
python scripts/daily_update.py --max-dates 1
```

Обрабатывает только одну дату (для тестирования).

## Особенности реализации

### Merge JSON данных

При обработке `change_type: "changed"` выполняется умное объединение данных:

1. **Маппинг полей с префиксом `new_`:**
   - `new_price` → `price`
   - `new_mileage` → `mileage`
   - И т.д.

2. **Сохранение существующих данных:**
   - Обновляются только измененные поля
   - Остальные поля остаются без изменений

3. **Пример:**
   ```python
   # Было в БД:
   {"price": 8000, "mark": "Kia", "year": 2020}
   
   # Пришло изменение:
   {"new_price": 7500}
   
   # Стало в БД:
   {"price": 7500, "mark": "Kia", "year": 2020}
   ```

### Rate Limiting

- Пауза 2 секунды между запросами к API
- Более консервативный подход, чем при первоначальной загрузке
- Предотвращает превышение лимитов API

### Обработка пропущенных дней

Модуль автоматически определяет, была ли дата уже обработана:
- Проверяется таблица `sync_state`
- Если дата уже обработана, процесс завершается без ошибок
- Это позволяет безопасно запускать модуль несколько раз в день

### Edge Cases

Модуль обрабатывает случаи, когда:
1. Приходит `change_type: "changed"` для несуществующей записи → создается новая запись
2. Приходит `change_type: "removed"` для несуществующей записи → создается запись с `active_status` = 1
3. Приходит `change_type: "added"` для существующей записи → пропускается как дубликат

## Зависимости

- `CHE168Client` - клиент для работы с API
- `BaseLoader` - базовый класс с общей логикой
- `RawData` - модель базы данных
- `SyncState` - модель состояния синхронизации
- `merge_json` - функция для объединения JSON данных
- `AsyncSessionLocal` - сессия базы данных
- `logger` - система логирования

## Логирование

Все операции логируются в `logs/app.log`:
- Начало и завершение операции
- Прогресс по страницам
- Статистика по типам изменений
- Ошибки с контекстом
- Статистика завершения

## Статистика

Модуль возвращает статистику:
- `dates_processed` - количество обработанных дат
- `total_loaded` - количество новых записей
- `total_updated` - количество обновленных записей
- `total_removed` - количество удаленных записей
- `total_duplicates` - количество пропущенных дубликатов
- `total_errors` - количество ошибок

## Пример вывода

```
[INFO] Processing date: 2025-02-08
[INFO] Got initial change_id: 123456789 for date 2025-02-08
[INFO] Starting pagination...
[INFO] Daily update: Page 1 | Records: 20 | Loaded: 5 | Updated: 10 | Removed: 5 | Duplicates: 0
[INFO] Daily update: Page 2 | Records: 40 | Loaded: 10 | Updated: 20 | Removed: 10 | Duplicates: 0
...
[INFO] Pagination complete: processed 50 page(s), 1000 records
[INFO] Daily update completed for 2025-02-08: pages=50, loaded=200, updated=600, removed=200, duplicates=0, errors=0
```

## Рекомендации по использованию

1. **Запуск через Cron:**
   - Настроить ежедневный запуск в определенное время (например, 02:00)
   - После завершения запускать модуль нормализации

2. **Мониторинг:**
   - Проверять логи на наличие ошибок
   - Следить за статистикой операций в таблице `operations_log`

3. **Обработка ошибок:**
   - При ошибках модуль не обновляет `sync_state`
   - Можно безопасно перезапустить модуль
   - Он продолжит с того же места
